{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/nguyenan362/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/nguyenan362/.local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /home/nguyenan362/.local/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in /home/nguyenan362/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in /home/nguyenan362/.local/lib/python3.10/site-packages (1.15.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nguyenan362/.local/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nguyenan362/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/nguyenan362/.local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nguyenan362/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/nguyenan362/.local/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nguyenan362/.local/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nguyenan362/.local/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/nguyenan362/.local/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nguyenan362/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/nguyenan362/.local/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/nguyenan362/.local/lib/python3.10/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nguyenan362/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting dask\n",
      "  Downloading dask-2025.2.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from dask) (5.4.1)\n",
      "Collecting cloudpickle>=3.0.0\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nguyenan362/.local/lib/python3.10/site-packages (from dask) (24.2)\n",
      "Requirement already satisfied: click>=8.1 in /home/nguyenan362/.local/lib/python3.10/site-packages (from dask) (8.1.8)\n",
      "Collecting fsspec>=2021.09.0\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 KB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting toolz>=0.10.0\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting partd>=1.4.0\n",
      "  Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Collecting importlib_metadata>=4.13.0\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=3.20\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Collecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: zipp, toolz, locket, fsspec, cloudpickle, partd, importlib_metadata, dask\n",
      "Successfully installed cloudpickle-3.1.1 dask-2025.2.0 fsspec-2025.2.0 importlib_metadata-8.6.1 locket-1.0.0 partd-1.4.2 toolz-1.0.0 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting narwhals>=1.15.1\n",
      "  Downloading narwhals-1.29.0-py3-none-any.whl (305 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 KB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/nguyenan362/.local/lib/python3.10/site-packages (from plotly) (24.2)\n",
      "Installing collected packages: narwhals, plotly\n",
      "Successfully installed narwhals-1.29.0 plotly-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/_compatibility.py:114\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, min_version, errors)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/__init__.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_collection_type\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backends, dispatch\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdask_expr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     DataFrame,\n\u001b[1;32m     27\u001b[0m     Index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     to_timedelta,\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Aggregation\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/backends.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpercentile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _percentile\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CreationDispatch, DaskBackendEntrypoint\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PANDAS_GE_220, is_any_real_numeric_dtype\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     categorical_dtype_dispatch,\n\u001b[1;32m     17\u001b[0m     concat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     union_categoricals_dispatch,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_array_nonempty, make_scalar\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/_compat.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/_compatibility.py:117\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, min_version, errors)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import datetime as dt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from collections import defaultdict\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import csv\n",
    "import dask.dataframe as dd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Đọc file lịch sử nghe nhạc\n",
    "    listening_history = pd.read_csv('sample_listening_history.tsv', \n",
    "                                    sep='\\t', \n",
    "                                    names=['userid', 'timestamp', 'artid', 'artname', 'traid', 'traname'])\n",
    "    \n",
    "    # Đọc file thông tin người dùng\n",
    "    user_profiles = pd.read_csv('dataset/userid-profile.tsv', \n",
    "                               sep='\\t',\n",
    "                               names=['userid', 'gender', 'age', 'country', 'signup'])\n",
    "    \n",
    "    # Chỉ giữ lại thông tin của các người dùng có trong mẫu listening_history\n",
    "    unique_users = listening_history['userid'].unique()\n",
    "    user_profiles = user_profiles[user_profiles['userid'].isin(unique_users)]\n",
    "    \n",
    "    return listening_history, user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(listening_history, user_profiles):\n",
    "    # Xử lý timestamp\n",
    "    listening_history['timestamp'] = pd.to_datetime(listening_history['timestamp'])\n",
    "    \n",
    "    # Xử lý các giá trị rỗng trong user_profiles\n",
    "    user_profiles['gender'].fillna('unknown', inplace=True)\n",
    "    user_profiles['age'].fillna(-1, inplace=True)\n",
    "    user_profiles['country'].fillna('unknown', inplace=True)\n",
    "    user_profiles['signup'].fillna(pd.Timestamp.now().date(), inplace=True)\n",
    "    \n",
    "    # Chuyển đổi kiểu dữ liệu\n",
    "    user_profiles['age'] = user_profiles['age'].astype(float).astype('Int64')\n",
    "    user_profiles['signup'] = pd.to_datetime(user_profiles['signup'])\n",
    "    \n",
    "    # Kết hợp dữ liệu từ cả hai bảng\n",
    "    combined_data = pd.merge(listening_history, user_profiles, on='userid', how='left')\n",
    "    \n",
    "    return listening_history, user_profiles, combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân tích xu hướng nghe nhạc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_listening_trends(combined_data):\n",
    "    # Thời điểm nghe trong ngày\n",
    "    combined_data['hour'] = combined_data['timestamp'].dt.hour\n",
    "    hourly_plays = combined_data.groupby('hour').size()\n",
    "    \n",
    "    # Nghệ sĩ phổ biến nhất\n",
    "    top_artists = combined_data.groupby('artname').size().sort_values(ascending=False).head(10)\n",
    "    \n",
    "    # Bài hát phổ biến nhất\n",
    "    top_tracks = combined_data.groupby('traname').size().sort_values(ascending=False).head(10)\n",
    "    \n",
    "    # Phân tích theo quốc gia\n",
    "    country_plays = combined_data.groupby('country').size().sort_values(ascending=False).head(10)\n",
    "    \n",
    "    # Phân tích theo độ tuổi\n",
    "    age_groups = pd.cut(combined_data['age'], bins=[-2, 0, 18, 25, 35, 50, 100], \n",
    "                         labels=['Unknown', '<18', '18-25', '26-35', '36-50', '>50'])\n",
    "    combined_data['age_group'] = age_groups\n",
    "    age_plays = combined_data.groupby('age_group').size()\n",
    "    \n",
    "    return hourly_plays, top_artists, top_tracks, country_plays, age_plays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trực quan hóa xu hướng nghe nhạc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trends(hourly_plays, top_artists, top_tracks, country_plays, age_plays):\n",
    "    # Tạo subplot grid\n",
    "    plt.figure(figsize=(18, 15))\n",
    "    \n",
    "    # 1. Biểu đồ thời điểm nghe trong ngày\n",
    "    plt.subplot(2, 2, 1)\n",
    "    hourly_plays.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Distribution of Listening Time During Day')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Number of Plays')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Biểu đồ nghệ sĩ phổ biến\n",
    "    plt.subplot(2, 2, 2)\n",
    "    top_artists.plot(kind='barh', color='salmon')\n",
    "    plt.title('Top 10 Most Popular Artists')\n",
    "    plt.xlabel('Number of Plays')\n",
    "    plt.ylabel('Artist')\n",
    "    \n",
    "    # 3. Biểu đồ bài hát phổ biến\n",
    "    plt.subplot(2, 2, 3)\n",
    "    top_tracks.plot(kind='barh', color='lightgreen')\n",
    "    plt.title('Top 10 Most Popular Tracks')\n",
    "    plt.xlabel('Number of Plays')\n",
    "    plt.ylabel('Track Name')\n",
    "    \n",
    "    # 4. Biểu đồ độ tuổi\n",
    "    plt.subplot(2, 2, 4)\n",
    "    age_plays.plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette(\"pastel\"))\n",
    "    plt.title('Listening Distribution by Age Group')\n",
    "    plt.ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tạo ma trận user-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(listening_history):\n",
    "    # Tạo ma trận người dùng-bài hát\n",
    "    user_track_matrix = listening_history.groupby(['userid', 'traid']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Nếu ma trận quá lớn, có thể giảm kích thước\n",
    "    if user_track_matrix.shape[1] > 5000:\n",
    "        # Chọn những bài hát được nghe nhiều nhất\n",
    "        popular_tracks = listening_history['traid'].value_counts().head(5000).index\n",
    "        user_track_matrix = user_track_matrix[popular_tracks]\n",
    "    \n",
    "    return user_track_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng hệ thống đề xuất dựa trên nội dung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recommendations(listening_history, userid, n_recommendations=10):\n",
    "    # Tạo feature artist cho mỗi track\n",
    "    track_artist_df = listening_history[['traid', 'traname', 'artid', 'artname']].drop_duplicates()\n",
    "    \n",
    "    # Lấy danh sách các bài hát đã nghe của người dùng\n",
    "    user_tracks = listening_history[listening_history['userid'] == userid]['traid'].unique()\n",
    "    \n",
    "    # Tìm các nghệ sĩ từ bài hát đã nghe\n",
    "    user_artists = listening_history[\n",
    "        (listening_history['userid'] == userid) & \n",
    "        (listening_history['traid'].isin(user_tracks))\n",
    "    ]['artid'].value_counts().index.tolist()\n",
    "    \n",
    "    # Đề xuất bài hát từ các nghệ sĩ yêu thích\n",
    "    recommended_tracks = track_artist_df[\n",
    "        (track_artist_df['artid'].isin(user_artists)) & \n",
    "        (~track_artist_df['traid'].isin(user_tracks))\n",
    "    ].drop_duplicates('traid')\n",
    "    \n",
    "    # Đếm số lần xuất hiện của mỗi nghệ sĩ trong lịch sử nghe\n",
    "    artist_counts = listening_history[listening_history['userid'] == userid]['artid'].value_counts().to_dict()\n",
    "    \n",
    "    # Gán trọng số cho từng bài hát dựa trên độ phổ biến của nghệ sĩ\n",
    "    recommended_tracks['score'] = recommended_tracks['artid'].map(\n",
    "        lambda x: artist_counts.get(x, 0)\n",
    "    )\n",
    "    \n",
    "    # Sắp xếp và trả về kết quả\n",
    "    return recommended_tracks.sort_values('score', ascending=False).head(n_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng hệ thống đề xuất cộng tác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filtering_recommendations(user_track_matrix, userid, n_recommendations=10):\n",
    "    # Kiểm tra xem người dùng có trong ma trận hay không\n",
    "    if userid not in user_track_matrix.index:\n",
    "        return pd.DataFrame()  # Trả về DataFrame rỗng nếu không tìm thấy người dùng\n",
    "    \n",
    "    # Tính toán ma trận tương đồng\n",
    "    user_similarity = cosine_similarity(user_track_matrix)\n",
    "    user_similarity_df = pd.DataFrame(user_similarity, \n",
    "                                     index=user_track_matrix.index, \n",
    "                                     columns=user_track_matrix.index)\n",
    "    \n",
    "    # Tìm những người dùng tương tự\n",
    "    user_index = user_track_matrix.index.get_loc(userid)\n",
    "    similar_users = user_similarity_df.iloc[user_index].sort_values(ascending=False)[1:11]\n",
    "    \n",
    "    # Bài hát đã nghe của người dùng\n",
    "    user_listened = set(user_track_matrix.columns[user_track_matrix.loc[userid] > 0])\n",
    "    \n",
    "    # Tìm bài hát được nghe bởi người dùng tương tự mà người dùng hiện tại chưa nghe\n",
    "    recommendations = defaultdict(float)\n",
    "    \n",
    "    for similar_user, similarity in similar_users.items():\n",
    "        # Bỏ qua nếu similarity quá thấp\n",
    "        if similarity <= 0.1:\n",
    "            continue\n",
    "            \n",
    "        # Bài hát được nghe bởi người dùng tương tự\n",
    "        similar_user_tracks = set(user_track_matrix.columns[user_track_matrix.loc[similar_user] > 0])\n",
    "        \n",
    "        # Tìm bài hát mà người dùng tương tự đã nghe nhưng người dùng hiện tại chưa nghe\n",
    "        new_tracks = similar_user_tracks - user_listened\n",
    "        \n",
    "        # Thêm điểm cho mỗi bài hát dựa trên độ tương đồng\n",
    "        for track in new_tracks:\n",
    "            listen_count = user_track_matrix.loc[similar_user, track]\n",
    "            recommendations[track] += similarity * listen_count\n",
    "    \n",
    "    # Sắp xếp các đề xuất\n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Lấy top n recommendations\n",
    "    top_recommendations = sorted_recommendations[:n_recommendations]\n",
    "    \n",
    "    # Trả về danh sách track_ids\n",
    "    return [track_id for track_id, score in top_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá hệ thống đề xuất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(listening_history, user_track_matrix, test_users=10):\n",
    "    # Chọn ngẫu nhiên một số người dùng để đánh giá\n",
    "    test_user_ids = np.random.choice(user_track_matrix.index, min(test_users, len(user_track_matrix.index)), replace=False)\n",
    "    \n",
    "    # Lưu trữ kết quả\n",
    "    results = []\n",
    "    \n",
    "    for user_id in test_user_ids:\n",
    "        # Lấy đề xuất\n",
    "        content_recs = content_based_recommendations(listening_history, user_id, n_recommendations=10)\n",
    "        collab_recs = collaborative_filtering_recommendations(user_track_matrix, user_id, n_recommendations=10)\n",
    "        \n",
    "        # Đếm số bài hát được đề xuất\n",
    "        n_content_recs = len(content_recs)\n",
    "        n_collab_recs = len(collab_recs)\n",
    "        \n",
    "        results.append({\n",
    "            'userid': user_id,\n",
    "            'content_recommendations': n_content_recs,\n",
    "            'collaborative_recommendations': n_collab_recs\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trực quan hóa hệ thống đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_evaluation(eval_results):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Tạo dữ liệu cho biểu đồ\n",
    "    users = eval_results['userid']\n",
    "    content_recs = eval_results['content_recommendations']\n",
    "    collab_recs = eval_results['collaborative_recommendations']\n",
    "    \n",
    "    # Vẽ biểu đồ cột ghép\n",
    "    x = np.arange(len(users))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, content_recs, width, label='Content-based')\n",
    "    plt.bar(x + width/2, collab_recs, width, label='Collaborative')\n",
    "    \n",
    "    plt.xlabel('Users')\n",
    "    plt.ylabel('Number of Recommendations')\n",
    "    plt.title('Comparison of Recommendation Methods')\n",
    "    plt.xticks(x, [f'User {i+1}' for i in range(len(users))], rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trực quan hóa mạng lưới người dùng và bài hát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_user_track_network(listening_history, max_users=20, max_tracks=30):\n",
    "    # Giới hạn số lượng dữ liệu để biểu đồ không quá phức tạp\n",
    "    top_users = listening_history['userid'].value_counts().head(max_users).index\n",
    "    filtered_history = listening_history[listening_history['userid'].isin(top_users)]\n",
    "    \n",
    "    top_tracks = filtered_history['traname'].value_counts().head(max_tracks).index\n",
    "    filtered_history = filtered_history[filtered_history['traname'].isin(top_tracks)]\n",
    "    \n",
    "    # Tạo danh sách các cạnh\n",
    "    edges = filtered_history[['userid', 'traname']].drop_duplicates()\n",
    "    \n",
    "    # Tạo biểu đồ tương tác với Plotly\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Thêm các cạnh\n",
    "    for _, edge in edges.iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[edge['userid'], edge['traname']],\n",
    "            y=[0, 1],\n",
    "            mode='lines',\n",
    "            line=dict(width=0.5, color='#888'),\n",
    "            hoverinfo='none'\n",
    "        ))\n",
    "    \n",
    "    # Thêm các nút người dùng\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=top_users,\n",
    "        y=[0] * len(top_users),\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color='blue'),\n",
    "        text=top_users,\n",
    "        name='Users'\n",
    "    ))\n",
    "    \n",
    "    # Thêm các nút bài hát\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=top_tracks,\n",
    "        y=[1] * len(top_tracks),\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color='red'),\n",
    "        text=top_tracks,\n",
    "        name='Tracks'\n",
    "    ))\n",
    "    \n",
    "    # Cập nhật layout\n",
    "    fig.update_layout(\n",
    "        title='User-Track Network',\n",
    "        showlegend=True,\n",
    "        hovermode='closest',\n",
    "        margin=dict(b=20, l=5, r=5, t=40),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biểu đồ nhiệt để hiển thị mối tương quan giữa người dùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_user_similarity_heatmap(user_track_matrix, max_users=50):\n",
    "    # Giới hạn số lượng người dùng để biểu đồ không quá phức tạp\n",
    "    if len(user_track_matrix) > max_users:\n",
    "        # Chọn những người dùng có nhiều lượt nghe nhất\n",
    "        active_users = user_track_matrix.sum(axis=1).nlargest(max_users).index\n",
    "        user_track_subset = user_track_matrix.loc[active_users]\n",
    "    else:\n",
    "        user_track_subset = user_track_matrix\n",
    "    \n",
    "    # Tính toán ma trận tương đồng\n",
    "    user_similarity = cosine_similarity(user_track_subset)\n",
    "    \n",
    "    # Tạo DataFrame từ ma trận tương đồng\n",
    "    user_similarity_df = pd.DataFrame(\n",
    "        user_similarity, \n",
    "        index=user_track_subset.index, \n",
    "        columns=user_track_subset.index\n",
    "    )\n",
    "    \n",
    "    # Tạo biểu đồ nhiệt\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Tạo bảng màu từ xanh dương đến đỏ\n",
    "    colors = ['#EFF3FF', '#C6DBEF', '#9ECAE1', '#6BAED6', '#4292C6', '#2171B5', '#084594']\n",
    "    cmap = LinearSegmentedColormap.from_list('custom_blues', colors, N=100)\n",
    "    \n",
    "    # Vẽ biểu đồ nhiệt\n",
    "    sns.heatmap(user_similarity_df, \n",
    "               cmap=cmap,\n",
    "               vmin=0, \n",
    "               vmax=1, \n",
    "               square=True, \n",
    "               linewidths=.5, \n",
    "               cbar_kws={\"shrink\": .5})\n",
    "    \n",
    "    plt.title('User Similarity Heatmap (Cosine Similarity)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiển thị UI cho hệ thống đề xuất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations_for_user(listening_history, user_track_matrix, combined_data, userid):\n",
    "    # Lấy thông tin người dùng\n",
    "    user_info = combined_data[combined_data['userid'] == userid].iloc[0]\n",
    "    \n",
    "    # Lấy các bài hát đã nghe\n",
    "    listened_tracks = listening_history[listening_history['userid'] == userid]\n",
    "    top_listened = listened_tracks['traname'].value_counts().head(5)\n",
    "    \n",
    "    # Lấy đề xuất dựa trên nội dung\n",
    "    content_recs = content_based_recommendations(listening_history, userid)\n",
    "    \n",
    "    # Lấy đề xuất dựa trên lọc cộng tác\n",
    "    collab_tracks = collaborative_filtering_recommendations(user_track_matrix, userid)\n",
    "    \n",
    "    # Lấy tên bài hát từ ID\n",
    "    track_map = dict(zip(listening_history['traid'], listening_history['traname']))\n",
    "    collab_track_names = [track_map.get(track_id, \"Unknown\") for track_id in collab_tracks]\n",
    "    \n",
    "    # Hiển thị thông tin\n",
    "    print(f\"Music Recommendations for User: {userid}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"User Profile: Gender: {user_info['gender']}, Age: {user_info['age']}, Country: {user_info['country']}\")\n",
    "    print(\"\\nTop Listened Tracks:\")\n",
    "    for i, (track, count) in enumerate(top_listened.items(), 1):\n",
    "        print(f\"{i}. {track} - {count} plays\")\n",
    "    \n",
    "    print(\"\\nContent-Based Recommendations:\")\n",
    "    if not content_recs.empty:\n",
    "        for i, (_, row) in enumerate(content_recs.iterrows(), 1):\n",
    "            print(f\"{i}. {row['traname']} by {row['artname']}\")\n",
    "    else:\n",
    "        print(\"No content-based recommendations available.\")\n",
    "    \n",
    "    print(\"\\nCollaborative Filtering Recommendations:\")\n",
    "    if collab_track_names:\n",
    "        for i, track in enumerate(collab_track_names, 1):\n",
    "            print(f\"{i}. {track}\")\n",
    "    else:\n",
    "        print(\"No collaborative filtering recommendations available.\")\n",
    "    \n",
    "    # Trả về dữ liệu để trực quan hóa trong các biểu đồ\n",
    "    return {\n",
    "        'top_listened': top_listened,\n",
    "        'content_recs': content_recs['traname'] if not content_recs.empty else pd.Series(),\n",
    "        'collab_recs': pd.Series(collab_track_names)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trực quan hóa đề xuất cho người dùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_user_recommendations(rec_data):\n",
    "    # Tạo figure với 3 subplots\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15))\n",
    "    \n",
    "    # 1. Biểu đồ bài hát đã nghe\n",
    "    if not rec_data['top_listened'].empty:\n",
    "        rec_data['top_listened'].plot(kind='barh', ax=ax1, color='skyblue')\n",
    "        ax1.set_title('Top Listened Tracks')\n",
    "        ax1.set_xlabel('Number of Plays')\n",
    "        ax1.set_ylabel('Track Name')\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'No listening history data available', \n",
    "                horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    # 2. Biểu đồ đề xuất dựa trên nội dung\n",
    "    if not rec_data['content_recs'].empty:\n",
    "        rec_data['content_recs'].value_counts().plot(kind='barh', ax=ax2, color='salmon')\n",
    "        ax2.set_title('Content-Based Recommendations')\n",
    "        ax2.set_xlabel('Recommendation Score')\n",
    "        ax2.set_ylabel('Track Name')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No content-based recommendations available', \n",
    "                horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    # 3. Biểu đồ đề xuất dựa trên lọc cộng tác\n",
    "    if not rec_data['collab_recs'].empty:\n",
    "        rec_data['collab_recs'].value_counts().plot(kind='barh', ax=ax3, color='lightgreen')\n",
    "        ax3.set_title('Collaborative Filtering Recommendations')\n",
    "        ax3.set_xlabel('Recommendation Score')\n",
    "        ax3.set_ylabel('Track Name')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No collaborative filtering recommendations available', \n",
    "                horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm chạy toàn bộ quy trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Hàm chính\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mrun_recommendation_system\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m, in \u001b[0;36mrun_recommendation_system\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_recommendation_system\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     listening_history, user_profiles \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessing data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     listening_history, user_profiles, combined_data \u001b[38;5;241m=\u001b[39m preprocess_data(listening_history, user_profiles)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "def run_recommendation_system():\n",
    "    print(\"Loading data...\")\n",
    "    listening_history, user_profiles = load_data()\n",
    "    \n",
    "    print(\"Preprocessing data...\")\n",
    "    listening_history, user_profiles, combined_data = preprocess_data(listening_history, user_profiles)\n",
    "    \n",
    "    print(\"Analyzing listening trends...\")\n",
    "    hourly_plays, top_artists, top_tracks, country_plays, age_plays = analyze_listening_trends(combined_data)\n",
    "    \n",
    "    print(\"Creating user-item matrix...\")\n",
    "    user_track_matrix = create_user_item_matrix(listening_history)\n",
    "    \n",
    "    print(\"Visualizing trends...\")\n",
    "    trend_visualization = visualize_trends(hourly_plays, top_artists, top_tracks, country_plays, age_plays)\n",
    "    trend_visualization.show()\n",
    "    \n",
    "    print(\"Evaluating recommendation system...\")\n",
    "    eval_results = evaluate_recommendations(listening_history, user_track_matrix)\n",
    "    \n",
    "    print(\"Visualizing evaluation results...\")\n",
    "    eval_visualization = visualize_evaluation(eval_results)\n",
    "    eval_visualization.show()\n",
    "    \n",
    "    print(\"Visualizing user similarity heatmap...\")\n",
    "    similarity_heatmap = visualize_user_similarity_heatmap(user_track_matrix)\n",
    "    similarity_heatmap.show()\n",
    "    \n",
    "    # Chọn một người dùng để hiển thị đề xuất\n",
    "    random_user = np.random.choice(user_profiles['userid'].values)\n",
    "    \n",
    "    print(f\"\\nGenerating recommendations for random user: {random_user}\")\n",
    "    rec_data = display_recommendations_for_user(listening_history, user_track_matrix, combined_data, random_user)\n",
    "    \n",
    "    print(\"Visualizing recommendations...\")\n",
    "    rec_visualization = visualize_user_recommendations(rec_data)\n",
    "    rec_visualization.show()\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "# Hàm chính\n",
    "if __name__ == \"__main__\":\n",
    "    run_recommendation_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
